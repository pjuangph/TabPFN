name: CI
on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

concurrency:
  group: pr-${{ github.ref }}
  cancel-in-progress: true

jobs:
  check_python_linting:
    name: Ruff Linting & Formatting
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
      - uses: astral-sh/ruff-action@57714a7c8a2e59f32539362ba31877a1957dded1 # v3.5.1
        with:
          version-file: pyproject.toml
      - uses: astral-sh/ruff-action@57714a7c8a2e59f32539362ba31877a1957dded1 # v3.5.1
        with:
          args: "format --check"
          version-file: pyproject.toml

  test_compatibility:
    name: Test Package Compatibility
    # This job will only start after linting succeeds
    needs: check_python_linting
    strategy:
      fail-fast: false
      matrix:
        # ubuntu-latest 3.14 highest is not included here because it is executed as a
        # separate workflow below. This is because we wish to gate the GPU workflow on
        # it, which requires a separate workflow.
        include:
          - os: ubuntu-latest
            python-version: "3.9"
            dependency-set: lowest-direct
          - os: macos-15-intel # We need x86 as ARM is python>= 3.11 only.
            # https://github.com/actions/setup-python/issues/855
            python-version: "3.9"
            dependency-set: lowest-direct
          - os: windows-latest
            python-version: "3.9"
            dependency-set: lowest-direct
          - os: macos-latest
            python-version: "3.14"
            dependency-set: highest
          - os: windows-latest
            python-version: "3.14"
            dependency-set: highest
    runs-on: ${{ matrix.os }}
    env:
      TABPFN_MODEL_CACHE_DIR: ${{ github.workspace }}/model_cache
      HF_TOKEN: ${{ vars.TABPFN_2_5_HF_TOKEN }}

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64

      - name: Install uv
        uses: astral-sh/setup-uv@ed21f2f24f8dd64503750218de024bcf64c7250a # v7.1.5
        with:
          enable-cache: true

      - name: Install dependencies
        run: uv sync --group ci --resolution ${{ matrix.dependency-set }}

      - name: "Check for forbidden licenses"
        shell: bash
        run: |
          uv run --no-sync licensecheck \
            --requirements-paths pyproject.toml \
            --show-only-failing \
            -0

      # We use a cache for the model checkpoints. This allows PRs from forks, which
      # can't access the HF_TOKEN, to have access to the model files. It also speeds up
      # PRs and avoids flakes.
      - &restore-model-cache
        name: Restore model cache
        id: restore-model-cache
        uses: actions/cache/restore@9255dc7a253b0ccc959486e2bca901246202afeb # v5.0.1
        with:
          path: ${{ github.workspace }}/model_cache
          key: model-cache-${{ hashFiles('model_cache/**') }}
          restore-keys: |
            model-cache-
          enableCrossOsArchive: true

      - &download-models
        name: Download models from Hugging Face
        run: uv run --no-sync python scripts/download_all_models.py

      - &save-model-cache
        name: Save model cache
        uses: actions/cache/save@9255dc7a253b0ccc959486e2bca901246202afeb # v5.0.1
        with:
          path: ${{ github.workspace }}/model_cache
          key: model-cache-${{ hashFiles('model_cache/**') }}
          enableCrossOsArchive: true

      - name: Run Tests (all tests)
        if: ${{ matrix.dependency-set != 'lowest-direct' && github.event_name != 'pull_request' }}
        run: uv run --no-sync pytest tests/

      - name: Run Tests (PR tests only)
        if: ${{ matrix.dependency-set != 'lowest-direct' && github.event_name == 'pull_request' }}
        run: uv run --no-sync pytest -m "not slow" tests/

      # We don't support MPS below PyTorch 2.5 (see tabpfn.utils.infer_devices()), thus
      # disable MPS for the lowest-direct dependency set.

      - name: Run Tests (all tests, MPS disabled)
        if: ${{ matrix.dependency-set == 'lowest-direct' && github.event_name != 'pull_request' }}
        env:
          TABPFN_EXCLUDE_DEVICES: mps
        run: uv run --no-sync pytest tests/

      - name: Run Tests (PR tests only, MPS disabled)
        if: ${{ matrix.dependency-set == 'lowest-direct' && github.event_name == 'pull_request' }}
        env:
          TABPFN_EXCLUDE_DEVICES: mps
        run: uv run --no-sync pytest -m "not slow" tests/

  # -------------------------------------------------------------------
  # Ubuntu-latest + highest dependencies (used as gate for GPU)
  # -------------------------------------------------------------------
  test_ubuntu_latest_314:
    name: Test Ubuntu-latest (Py 3.14)
    needs: check_python_linting
    runs-on: ubuntu-latest
    env:
      TABPFN_MODEL_CACHE_DIR: ${{ github.workspace }}/model_cache
      HF_TOKEN: ${{ vars.TABPFN_2_5_HF_TOKEN }}

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Set up Python 3.14
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: "3.14"
          architecture: x64

      - name: Install uv
        uses: astral-sh/setup-uv@ed21f2f24f8dd64503750218de024bcf64c7250a # v7.1.5
        with:
          enable-cache: true

      - name: Install dependencies
        run: uv sync --group ci --resolution highest
        shell: bash

      - name: "Check for forbidden licenses"
        shell: bash
        run: |
          uv run --no-sync licensecheck \
            --requirements-paths pyproject.toml \
            --show-only-failing \
            -0

      - *restore-model-cache
      - *download-models
      - *save-model-cache

      - name: Run Tests
        run: uv run --no-sync pytest tests/

  # -------------------------------------------------------------------
  # GPU: To save compute we only want to execute this workflow once
  # a CPU workflow has passed. Hence, this workflow depends on the
  # ubuntu-latest 3.14 workflow above.
  # -------------------------------------------------------------------
  test_gpu:
    name: Test on GPU
    needs: test_ubuntu_latest_314

    strategy:
      fail-fast: false
      matrix:
        include:
          - python-version: "3.9"
            dependency-set: lowest-direct
          - python-version: "3.14"
            dependency-set: highest

    runs-on: ubuntu-22.04-4core-gpu
    env:
      TABPFN_MODEL_CACHE_DIR: ${{ github.workspace }}/model_cache
      HF_TOKEN: ${{ vars.TABPFN_2_5_HF_TOKEN }}

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64

      - name: Install uv
        uses: astral-sh/setup-uv@ed21f2f24f8dd64503750218de024bcf64c7250a # v7.1.5
        with:
          enable-cache: true

      - name: Install dependencies
        run: uv sync --group ci --resolution ${{ matrix.dependency-set }}

      - *restore-model-cache
      - *download-models
      - *save-model-cache

      - name: Run GPU Test Suite
        env:
          CUDA_VISIBLE_DEVICES: "0"
          # skip cpu based tests that were run separately
          TABPFN_EXCLUDE_DEVICES: "cpu,cpu:0,mps"
        run: uv run --no-sync pytest tests/
